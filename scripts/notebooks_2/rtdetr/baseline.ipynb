{
  "cells": [
    {"cell_type":"markdown","metadata":{},"source":["# FPUS23 — RT‑DETR Baseline (original, no noise)\n","\n","Trains RT‑DETR on original FPUS23 COCO train/val (no balancing, no denoise).\n","Saves checkpoints and mAP metrics to Drive."]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Install\n","!pip -q install pycocotools 'transformers>=4.43' 'accelerate>=0.31' timm tqdm\n","from google.colab import drive; drive.mount('/content/drive', force_remount=True)\n","DRIVE_DIR = '/content/drive/MyDrive/FPUS23_transformers'\n","import pathlib as p; p.Path(DRIVE_DIR).mkdir(parents=True, exist_ok=True)\n","print('Saving to:', DRIVE_DIR)\n"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Paths (baseline)\n","COCO_ROOT = '/content/fpus23_project/dataset/fpus23_coco'\n","TRAIN_JSON = f"{COCO_ROOT}/train.json"\n","VAL_JSON   = f"{COCO_ROOT}/val.json"\n","TRAIN_DIR  = f"{COCO_ROOT}/train"\n","VAL_DIR    = f"{COCO_ROOT}/val"\n","!ls -lh $TRAIN_DIR | head -5\n","!ls -lh $VAL_DIR   | head -5\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Train — RT‑DETR r50vd (baseline)"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["MODEL='PekingU/rtdetr_r50vd'\n","EPOCHS=20; BATCH=8; LR=5e-5\n","OUTDIR=f"{DRIVE_DIR}/rtdetr_baseline"\n","!python 'New folder/scripts/train_rtdetr_fpus23.py' \\\n","  --annotations-dir $COCO_ROOT \\\n","  --images-dir $COCO_ROOT \\\n","  --train-json $TRAIN_JSON \\\n","  --val-json $VAL_JSON \\\n","  --train-images $TRAIN_DIR \\\n","  --val-images $VAL_DIR \\\n","  --model $MODEL \\\n","  --epochs $EPOCHS \\\n","  --batch $BATCH \\\n","  --lr $LR \\\n","  --output-dir $OUTDIR\n"]},
    {"cell_type":"markdown","metadata":{},"source":["## Evaluate on val (COCO mAP)"]},
    {"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","import json, torch\n","from PIL import Image\n","from tqdm import tqdm\n","from pycocotools.coco import COCO\n","from pycocotools.cocoeval import COCOeval\n","from transformers import RTDetrForObjectDetection, RTDetrImageProcessor as Proc\n","VAL_JSON = '/content/fpus23_project/dataset/fpus23_coco/val.json'\n","VAL_DIR  = '/content/fpus23_project/dataset/fpus23_coco/val'\n","proc = Proc.from_pretrained(OUTDIR + '/final')\n","model = RTDetrForObjectDetection.from_pretrained(OUTDIR + '/final').eval().to('cuda')\n","coco = COCO(VAL_JSON)\n","img_ids = coco.getImgIds()\n","preds = []\n","for img_id in tqdm(img_ids, desc='Val inference'):\n","    meta = coco.loadImgs([img_id])[0]\n","    im = Image.open(Path(VAL_DIR)/meta['file_name']).convert('RGB')\n","    inputs = proc(images=im, return_tensors='pt').to('cuda')\n","    with torch.no_grad():\n","        out = model(**inputs)\n","    res = proc.post_process_object_detection(out, target_sizes=[im.size[::-1]], threshold=0.001)[0]\n","    for s, l, b in zip(res['scores'], res['labels'], res['boxes']):\n","        x1,y1,x2,y2 = b.tolist(); preds.append({'image_id':img_id,'category_id':int(l)+1,'bbox':[x1,y1,x2-x1,y2-y1],'score':float(s)})\n","pred_path = Path(OUTDIR)/'preds_val.json'; json.dump(preds, open(pred_path,'w'))\n","dt = coco.loadRes(str(pred_path))\n","ev = COCOeval(coco, dt, iouType='bbox'); ev.evaluate(); ev.accumulate(); ev.summarize()\n","Path(OUTDIR/'metrics_val.json').write_text(json.dumps({'stats': ev.stats.tolist()}))\n","print('Saved metrics to', OUTDIR)\n"]}
  ],
  "metadata": {"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10"}},
  "nbformat": 4,
  "nbformat_minor": 2
}
